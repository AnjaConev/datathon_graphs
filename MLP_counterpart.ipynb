{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import random \n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, nn\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric import data as DATA\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "from torch_geometric.utils import negative_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "effort = \"MLP_DOC2Vec\"\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rf27/miniconda3/envs/New_awesome_environment/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3172: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "edge_folds = pd.read_csv(\"./data_split.csv\", header=0)\n",
    "edge_folds = edge_folds[edge_folds['Label'] == 1]\n",
    "edge_folds.loc[edge_folds['Fold'] == 'Test', 'Fold'] = 5\n",
    "edge_folds.loc[edge_folds['Fold'] == '3', 'Fold'] = 3\n",
    "edge_folds.loc[edge_folds['Fold'] == '4', 'Fold'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_channels * 2, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.fc3 = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        x = torch.cat((z[edge_label_index[0]], z[edge_label_index[1]]), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out.cpu(), edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    \n",
    "    # We perform a new round of negative sampling for every validation:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index = data.edge_index, num_nodes=data.num_nodes,\n",
    "        num_neg_samples = data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    \n",
    "    edge_label = torch.cat([\n",
    "        data.edge_label,\n",
    "        data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "    \n",
    "    out = model.decode(z, edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text type features\n",
    "features = pd.read_csv(\"./DOC2Vec_features.csv\")\n",
    "features = features.sort_values(by=['id'])\n",
    "\n",
    "# PCA ONLY on TF_IDF\n",
    "\n",
    "# Page type features\n",
    "page_type = pd.read_csv(\"./Training/node_classification.csv\")\n",
    "myEncoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "myEncoder.fit(page_type['page_type'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "page_type = pd.concat([page_type.drop('page_type', 1),\n",
    "            pd.DataFrame(myEncoder.transform(page_type['page_type'].to_numpy().reshape(-1, 1)))], \n",
    "                         axis=1).reindex()\n",
    "\n",
    "# Node Id Embedding features\n",
    "embedding = torch.nn.Embedding(page_type.shape[0], 32)\n",
    "embedding = pd.DataFrame(np.array(embedding.weight.data))\n",
    "embedding['id'] = range(page_type.shape[0])\n",
    "\n",
    "# Finalize Feature Embedding\n",
    "features = features.merge(page_type, how='inner', on='id').merge(embedding, how='inner', on='id')\n",
    "features = features.drop(columns=['id'])\n",
    "\n",
    "features = torch.Tensor(features.to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split # 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4354/3788061679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mG_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas_edgelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_folds_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Node1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Node2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0medge_label_index_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/New_awesome_environment/lib/python3.9/site-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mfrom_pandas_edgelist\u001b[0;34m(df, source, target, edge_attr, create_using, edge_key)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/New_awesome_environment/lib/python3.9/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjlist_inner_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0mdatadict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in range(1, 6):\n",
    "    \n",
    "    with open('./logs/' + effort + '_fold' + str(r) +'.txt', 'w') as f:\n",
    "        f.write(\"New training bitches!!\\n\")\n",
    "    \n",
    "    print(\"Split #\", r)\n",
    "    with open('./logs/' + effort + '_fold' + str(r) + '.txt', 'a') as f:\n",
    "        f.write(\"Split # {}\\n\".format(r))\n",
    "        \n",
    "    edge_folds_train = edge_folds[edge_folds['Fold'] != r]\n",
    "    edge_folds_val = edge_folds[edge_folds['Fold'] == r]\n",
    "    G = nx.from_pandas_edgelist(edge_folds_train, 'Node1', 'Node2')\n",
    "\n",
    "    edge_index = []\n",
    "    for e1, e2 in G.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "    \n",
    "    G_val = nx.from_pandas_edgelist(edge_folds_val, 'Node1', 'Node2')\n",
    "    edge_label_index_val = []\n",
    "    for e1, e2 in G_val.edges:\n",
    "        edge_label_index_val.append([e1, e2])\n",
    "        \n",
    "    train_graph = DATA.Data(\n",
    "        x = features.to(device),\n",
    "        edge_index = torch.LongTensor(edge_index).transpose(1, 0).to(device),\n",
    "        edge_label_index = torch.LongTensor(edge_index).transpose(1, 0).to(device),\n",
    "        edge_label = torch.ones(len(edge_index))\n",
    "    )\n",
    "    \n",
    "    val_graph = DATA.Data(\n",
    "        x = features.to(device),\n",
    "        edge_index = torch.LongTensor(edge_index).transpose(1, 0).to(device),\n",
    "        edge_label_index = torch.LongTensor(edge_label_index_val).transpose(1, 0).to(device),\n",
    "        edge_label = torch.ones(len(edge_label_index_val))\n",
    "    )\n",
    "    \n",
    "    model = Net(164, 128, 64).to(device) # Change number of features accordingly\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    best_val_auc = 0\n",
    "    for epoch in range(1, 1001):\n",
    "        loss = train(train_graph)\n",
    "        print('Train epoch: {}, Total Loss: {:.4f}'.format(epoch, loss))\n",
    "        with open('./logs/' + effort + '_fold' + str(r) + '.txt', 'a') as f:\n",
    "            f.write('Train epoch: {}, Total Loss: {:.4f}\\n'.format(epoch, loss))  \n",
    "        val_auc = test(val_graph)\n",
    "        print('Total Validation AUC: {:.4f}'.format(val_auc))\n",
    "        with open('./logs/' + effort + '_fold' + str(r) + '.txt', 'a') as f:\n",
    "            f.write('Total Validation AUC: {:.4f}'.format(val_auc))  \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val = val_auc\n",
    "            torch.save(model.state_dict(), \n",
    "                       './models/' + effort + '_fold' + str(r) + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
